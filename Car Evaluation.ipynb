{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"car.data\",names=[\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null or missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      False\n",
       "maint       False\n",
       "doors       False\n",
       "persons     False\n",
       "lug_boot    False\n",
       "safety      False\n",
       "labels      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration about classes to be classified or predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'vgood', 'good'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"labels\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount of data availaible for each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unacc --> (1210, 7)\n",
      "acc--> (384, 7)\n",
      "vgood--> (65, 7)\n",
      "good--> (69, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"unacc -->\",df[df[\"labels\"]==\"unacc\"].shape)\n",
    "print(\"acc-->\",df[df[\"labels\"]==\"acc\"].shape)\n",
    "print(\"vgood-->\",df[df[\"labels\"]==\"vgood\"].shape)\n",
    "print(\"good-->\",df[df[\"labels\"]==\"good\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying--> ['vhigh' 'high' 'med' 'low']\n",
      " \n",
      "maint--> ['vhigh' 'high' 'med' 'low']\n",
      " \n",
      "doors--> ['2' '3' '4' '5more']\n",
      " \n",
      "person--> ['2' '4' 'more']\n",
      " \n",
      "lug_boot--> ['small' 'med' 'big']\n",
      " \n",
      "safety--> ['low' 'med' 'high']\n"
     ]
    }
   ],
   "source": [
    "print(\"buying-->\",df[\"buying\"].unique())\n",
    "print(\" \")\n",
    "print(\"maint-->\",df[\"maint\"].unique())\n",
    "print(\" \")\n",
    "print(\"doors-->\",df[\"doors\"].unique())\n",
    "print(\" \")\n",
    "print(\"person-->\",df[\"persons\"].unique())\n",
    "print(\" \")\n",
    "print(\"lug_boot-->\",df[\"lug_boot\"].unique())\n",
    "print(\" \")\n",
    "print(\"safety-->\",df[\"safety\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the Categorical features into number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracting input and output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "Y=df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder=OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1728x21 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10368 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneHotEncoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoder vs Label encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoder  ## Input->[\"India\",\"Nepal\"] then it creates two collumns with India->[1,0] and nepal with[0,1] values \n",
    "## Label Encoder   ##Input-> [\"India\",\"Nepal\"] then it return one array with [0,1] meaning 0 for India and 1 for Nepal \n",
    "## Label Encoder is used for cases EX: Input-->[\"low\",\"medium\",\"high\"]  which returns us [0,1,2]\n",
    "## where there is some kind of relationshiop between values\n",
    "## so we will ditch One Hot Encoder in this case and use Labe Encoder for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np ## importing numpy for saving of Encoders for new incoming test data\n",
    "# np.load(\"safety.npy\",allow_pickle=True) ## for encoding new test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Every Categorical Variables and saving an encoder for future inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GSC-30397\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py:576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "C:\\Users\\GSC-30397\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "X.loc[:,'safety']=LE.fit_transform(X[\"safety\"])\n",
    "np.save(\"safety.npy\",LE.classes_)\n",
    "\n",
    "X.loc[:,'buying']=LE.fit_transform(X[\"buying\"])\n",
    "np.save(\"buying.npy\",LE.classes_)\n",
    "\n",
    "X.loc[:,'lug_boot']=LE.fit_transform(X[\"lug_boot\"])\n",
    "np.save(\"lug_boot.npy\",LE.classes_)\n",
    "\n",
    "X.loc[:,'maint']=LE.fit_transform(X[\"maint\"])\n",
    "np.save(\"maint.npy\",LE.classes_)\n",
    "\n",
    "X.loc[:,'doors']=LE.fit_transform(X[\"doors\"])\n",
    "np.save(\"doors.npy\",LE.classes_)\n",
    "\n",
    "X.loc[:,'persons']=LE.fit_transform(X[\"persons\"])\n",
    "np.save(\"persons.npy\",LE.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GSC-30397\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\GSC-30397\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Y[\"labels\"]=LE.fit_transform(Y)\n",
    "np.save(\"labels.npy\",LE.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data before Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying--> ['vhigh' 'high' 'med' 'low']\n",
      " \n",
      "maint--> ['vhigh' 'high' 'med' 'low']\n",
      " \n",
      "doors--> ['2' '3' '4' '5more']\n",
      " \n",
      "person--> ['2' '4' 'more']\n",
      " \n",
      "lug_boot--> ['small' 'med' 'big']\n",
      " \n",
      "safety--> ['low' 'med' 'high']\n"
     ]
    }
   ],
   "source": [
    "print(\"buying-->\",df[\"buying\"].unique())\n",
    "print(\" \")\n",
    "print(\"maint-->\",df[\"maint\"].unique())\n",
    "print(\" \")\n",
    "print(\"doors-->\",df[\"doors\"].unique())\n",
    "print(\" \")\n",
    "print(\"person-->\",df[\"persons\"].unique())\n",
    "print(\" \")\n",
    "print(\"lug_boot-->\",df[\"lug_boot\"].unique())\n",
    "print(\" \")\n",
    "print(\"safety-->\",df[\"safety\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data after Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying--> [3 0 2 1]\n",
      " \n",
      "maint--> [3 0 2 1]\n",
      " \n",
      "doors--> [0 1 2 3]\n",
      " \n",
      "person--> [0 1 2]\n",
      " \n",
      "lug_boot--> [2 1 0]\n",
      " \n",
      "safety--> [1 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"buying-->\",X[\"buying\"].unique())\n",
    "print(\" \")\n",
    "print(\"maint-->\",X[\"maint\"].unique())\n",
    "print(\" \")\n",
    "print(\"doors-->\",X[\"doors\"].unique())\n",
    "print(\" \")\n",
    "print(\"person-->\",X[\"persons\"].unique())\n",
    "print(\" \")\n",
    "print(\"lug_boot-->\",X[\"lug_boot\"].unique())\n",
    "print(\" \")\n",
    "print(\"safety-->\",X[\"safety\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Saved Encoders for future inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying--> ['high' 'low' 'med' 'vhigh']\n",
      " \n",
      "maint--> ['high' 'low' 'med' 'vhigh']\n",
      " \n",
      "doors--> ['2' '3' '4' '5more']\n",
      " \n",
      "person--> ['2' '4' 'more']\n",
      " \n",
      "lug_boot--> ['big' 'med' 'small']\n",
      " \n",
      "safety--> ['high' 'low' 'med']\n",
      "///\n",
      "labels--> ['acc' 'good' 'unacc' 'vgood']\n"
     ]
    }
   ],
   "source": [
    "print(\"buying-->\",np.load(\"buying.npy\",allow_pickle=True))\n",
    "print(\" \")\n",
    "print(\"maint-->\",np.load(\"maint.npy\",allow_pickle=True))\n",
    "print(\" \")\n",
    "print(\"doors-->\",np.load(\"doors.npy\",allow_pickle=True))\n",
    "print(\" \")\n",
    "print(\"person-->\",np.load(\"persons.npy\",allow_pickle=True))\n",
    "print(\" \")\n",
    "print(\"lug_boot-->\",np.load(\"lug_boot.npy\",allow_pickle=True))\n",
    "print(\" \")\n",
    "print(\"safety-->\",np.load(\"safety.npy\",allow_pickle=True))\n",
    "print(\"///\")\n",
    "print(\"labels-->\",np.load(\"labels.npy\",allow_pickle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(X,Y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffrent Algorithms for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can try differene kernels for svm like linear rvf sigmoid and poly which tries to capture more information\n",
    "## about data points in higher dimenstions without actually projecting them into higher dimension. \n",
    "# RBF has worked best for me in this  problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_A=SVC(kernel='rbf',decision_function_shape='ovr',probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GSC-30397\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_A.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc=classifier_A.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9132947976878613"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Confusin matrix is the preferred evaluation metric for multiclass classification.\n",
    "# Working:\n",
    "##              predicted class \n",
    "# ground truth  0[0   1]--> O predicted as 0 or 1 \n",
    "#               1[0   1]--> 1 predicted as 0 or 1\n",
    "\n",
    "#     likewise \n",
    "# 0->[0 1 2 3]\n",
    "# 1->[0 1 2 3]\n",
    "# 2->[0 1 2 3]\n",
    "# 3->[0 1 2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 63,   0,  20,   0],\n",
       "       [  5,   5,   0,   1],\n",
       "       [  2,   0, 233,   0],\n",
       "       [  2,   0,   0,  15]], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tree based algorithms are suggested for catgorical data so let's try Random forest for this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GSC-30397\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_B = RandomForestClassifier(random_state=42,criterion='gini',bootstrap=True)\n",
    "classifier_B.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf=classifier_B.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739884393063584"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 75,   6,   2,   0],\n",
       "       [  0,  11,   0,   0],\n",
       "       [  0,   0, 235,   0],\n",
       "       [  1,   0,   0,  16]], dtype=int64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Once you have finalized the model just dump it for further predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier.pkl']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier_B,\"classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
